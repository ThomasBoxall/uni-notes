\taughtsession{Lecture}{A2: Grammars}{2025-09-29}{15:00}{Janka}{}

As we saw in the previous lecture, languages can be defined through giving a set of strings or combining from the existing languages using operations such as productions, unions, etc. Alternatively, we can use a grammar to define a language. 

To describe a grammar for a language - two collections of alphabets (symbols) are necessary.
\begin{define}
\item[Terminal] Symbols from which all strings in the language are made. They are symbols of a `given' alphabet for generated language. Usually represented using lower case letters
\item[Non-Terminal] Temporary Symbols (different to terminals) used to define the grammar replacement rules within the production rules. They must be replaced by terminals before the production can successfully make a valid string of the language. Usually represented using upper case letters.
\end{define}

Now we know what terminals \& non-terminals are - we need to know how to produce terminals from non-terminals. This is where the \textit{Production Rules} come into play. Productions take the form:
\[\alpha \rightarrow \beta\]
where $\alpha$ and $\beta$ are strings of symbols taken from the set of terminals and non-terminals. 

A grammar rule can be read in any of several ways:
\begin{multicols}{2}
    \begin{itemize}
        \item ``replace $\alpha$ by $\beta$''
        \item ``$\alpha$ produces $\beta$''
        \item ``$\alpha$ rewrites to $\beta$''
        \item ``$\alpha$ reduces to $\beta$''
    \end{itemize}
\end{multicols}
We can now define the grammar.

\begin{define}
\item[Grammar] A set of rules used to define a language - the structure of the strings in the language. There are four key components of a grammar:
\begin{enumerate}
    \item An alphabet $T$ of symbols called \textit{terminals} which are identical to the alphabet of the resulting language
    \item An alphabet $N$ of grammar symbols called \textit{non-terminals} which are used in the production rules
    \item A specific non-terminal called the \textit{start symbol} which is usually $S$
    \item A finite set of \textit{productions} of the form $\alpha \rightarrow \beta$ where $\alpha$ and $\beta$ are strings over the alphabet $N \cup T$
\end{enumerate}
\end{define}

\section{Using a Grammar to Generate a Language}
Every grammar has a special non-terminal symbol called a \textit{start symbol} and there must be at least one production with left-side consisting of only the start symbol. Starting from the production rules with the start symbol, we can step-by-step generate all strings belonging to the language described by a given grammar. 

As we begin converting from Non-Terminal to Terminal containing strings, we introduce the \textit{Sentential Form}. As we continue to generate strings, we introduce \textit{derivation}.
\begin{define}
    \item[Sentential Form] A string made up of terminal and non-terminal symbols.
    \item[Derivation] Where $x$ and $y$ are sentential forms and $\alpha \rightarrow \beta$ is a production, then the replacement of $\alpha$ with $\beta$ in $x \alpha y$ is called a derivation. We denote this by writing:
    \[ x \alpha y \Rightarrow x \beta y \]
\end{define}

During our derivations, there are three symbols we may come across:
\begin{itemize}
    \item $\Rightarrow$ derives in one step
    \item $\Rightarrow^+$ derives in one or more steps
    \item $\Rightarrow^*$ derives in zero or more steps
\end{itemize}

Finally, we can define $L(G)$: the Language defined by the given Grammar. 
\begin{define}
\item[$L(G)$] If $G$ is a grammar with start symbol $S$ and set of terminals $T$, then the language generated by $G$ is the following set:
\[L(G) = \{s | s \in T^* and S \Rightarrow^+ s\}\]
\end{define}

Great - now we've seen the theory, lets put it into an example.

\begin{example}{Using a Grammar to Derive a Language}
Let a grammar, $G$, be defined by:
\begin{itemize}
    \item the set of terminals $T = \{a, b\}$
    \item the only non-terminal start symbol $S$
    \item the set of production rules: $S \rightarrow \Lambda, \quad S \rightarrow aSb$\\
    or in shorthand: $S \rightarrow \Lambda | aSb$
\end{itemize}

Now, beginning the derivations. We have to start with the start symbol $S$, and we can either derive $\Lambda$ or $aSb$. Obviously deriving $\Lambda$ would end the production and deriving $aSb$ would allow  us to keep re-using the production rules:
\[S \Rightarrow aSb \Rightarrow aaSbb \Rightarrow aaaSbbb \Rightarrow \ldots\]

Using a combination of the two production rules, we can build up a picture of what strings we can derive from the start symbol:
\[S \Rightarrow \Lambda, S \Rightarrow aSb \Rightarrow ab\]
The second string above we can turn into the following shorthand:
\[S \Rightarrow^* ab\]
Or alternatively, we can use shorthand to jump forward and yet continue the derivation:
\[S \Rightarrow^* aaaSbbb\]

This brings us to the end of the example as we can now define $L(G)$:
\[L(G) = \{\Lambda, ab, aabb, aaabbb, \ldots\}\]

\end{example}

\begin{example}{Longer Derivation of a String}
    Let $\Sigma = \{a, b, c\}$ be the set of terminal symbols and $S$ be the only non-terminal symbol. We have four production rules:
    \begin{itemize}
        \item $S \rightarrow \Lambda$
        \item $S \rightarrow aS$
        \item $S \rightarrow bS$
        \item $S \rightarrow cS$
    \end{itemize}
    Which can alternatively be represented in Shorthand: $S \rightarrow \Lambda | aS | bS | cS$

    To derive the string $aacb$ we would undergo the following derivation:
    \[S \Rightarrow aS \Rightarrow aaS \Rightarrow aacS \Rightarrow aacbS \Rightarrow aacb\Lambda = aacb\]
    Which can be shortened to $S \Rightarrow^* aacb$

    Note how we started on the left and worked left-to-right. This makes this derivation a \textit{leftmost} derivation because we produced the leftmost characters first.
\end{example}

\section{Infinite Languages}
As in the previous example, note how there is no bound on the length of the strings in an infinite language. Therefore there is no bound on the number of derivation steps used to derive the strings. If the grammar has $n$ productions, then any derivation consisting of $n+1$ steps must use some production twice.

Where a language is infinite - some of the productions or sequence of productions must be used repeatedly to construct the derivations. 

\begin{example}{Infinite language}
Take the infinite language $\{a^nb | n \geq 0\}$ which can be described by the grammar $S \rightarrow b | aS$. 

To derive the string $a^nb$, the production $S \rightarrow aS$ is used repeatedly, $n$ times and then the derivation is stopped by using the production $S \rightarrow b$. 
\end{example}

The production $S \rightarrow aS$ allows us to say ``If $S$ derives $w$, then it also derives $aw$''. 


\section{Recursion / Indirect Recursion}
A production is called recursive if its left side occurs on it's right side. For example the production $S \rightarrow aS$ is recursive. 

A production $A \rightarrow \ldots$ is indirectly recursive if $A$ derives a sentential form that contains $A$ in two or more steps.
\begin{example} {Indirect Recursion}
If the grammar contains the rules $S \rightarrow b|aA, A \rightarrow c|bS$ then both productions $S \rightarrow aA$ and $A \rightarrow bS$ are indirectly recursive:
\begin{align*}
    S &\Rightarrow aA \Rightarrow abS\\
    A &\Rightarrow bS \Rightarrow baA
\end{align*}
\end{example}

A grammar can also be considered recursive where it contains either a recursive production or an indirectly recursive production. We can deduce from this that a grammar for an infinite language must be directly or indirectly recursive. 

\section{Constructing Grammars}
Up to now, we've looked at deriving a language from a given grammar. Now we will take the inverse - be given a language and construct a grammar which derives the specified language.

Sometimes it is difficult or even impossible to write down a grammar for a given language. Unsurprisingly, a language may have more than one grammar which is correct and valid.

\subsection{Finite Languages}
If the number of strings in a language is finite, then a grammar can consist of all productions of the form $S \rightarrow w$ for each string $w$ in the language. 

\begin{example}{Finite Language}
The finite language $\{a, ba\}$ can be described by the grammar:
\[S \rightarrow a|ba\]
\end{example}

\subsection{Infinite Languages}
To find the grammar for a language where the number of strings is infinite is a considerably bigger challenge. There is no universal method for finding a grammar for an infinite language, however the method of \textit{combining grammars} can prove useful. 

\begin{example}{Infinite Language}
To find a grammar for the following simple language:
\[\{\Lambda, a, aa, \ldots, a^n, \ldots\} = \{a^n : n \in \mathbb{N}\}\]

We can use the following solution:
\begin{itemize}
    \item We know the set of terminals: $T = \{a\}$
    \item We know the only non-terminal start symbol: $S$
    \item So therefore we can generate the production rules: $S \rightarrow \Lambda, S \rightarrow aS$
\end{itemize}
\end{example}

\section{Combining Grammars}
If we take $L$ and $M$ to be languages which we are able to find the grammars; then there exist simple rules for creating grammars which produce the languages $L \cup M$, $L \cdot M$, and $L^*$. This therefore means we can describe $L$ and $M$ with grammars having disjoint sets (where neither set has common elements) of non-terminals. 

The combination process is started by assigning start symbols for the grammars of $L$ and $M$ to be $A$ and $B$ respectively:
\[L:A \rightarrow \ldots, \quad M:B \rightarrow \ldots \]

\subsection{Union Rule}
The union of two languages, $L \cup M$ starts with the two productions:
\[S \rightarrow A|B\]
which is followed by: the grammar rules of $L$ (start symbol $A$) and then the grammar rules of $M$ (start symbol $B$).

\begin{example}{Combining Grammars Using Union Rule}
If we take the following language:
\[K =\{\Lambda, a, b, aa, bb, aaa, bbb, \ldots, a^n, b^n, \ldots\}\]
Now to find the grammar for it. 

Firstly we look at it and see quite clearly there is a pattern, $K$ is a union of the two languages:
\[L = \{a^n | n \in \mathbb{N}\} \ \mathrm{and}\ M = \{b^n | n \in \mathbb{N}\} \]

Therefore we can write a grammar for $K$ as follows:
\begin{itemize}
    \item $A \rightarrow \Lambda | aA$ (grammar for $L$)
    \item $B \rightarrow \Lambda | bB$ (grammar for $M$)
    \item $S \rightarrow A|B$ (union rule)
\end{itemize}
    
\end{example}

\subsection{Product Rule}
Much the same as the Union Rule, the product of two languages, $L \cdot M$ starts with the production:
\[S \rightarrow AB\]
Which is then followed by: the grammar rules of $L$ (start symbol $A$) and then the grammar rules of $M$ (start symbol $B$).

\begin{example}{Combining Grammars Using Product Rule}
If we take the following language:
\begin{align*}
    K &= \{a^mb^n | m, n \in \mathbb{N}\}\\
    &= \{\Lambda, a, b, aa, ab, aaa, bb\}
\end{align*}
We can first find out that $K$ is the product of two languages:
\[L = \{a^n | n \in \mathbb{N}\} \ \mathrm{and}\ M = \{b^n | n \in \mathbb{N}\} \]

Therefore we can write a grammar for $K$ as follows:
\begin{itemize}
    \item $A \rightarrow \Lambda | aA$ (grammar for $L$)
    \item $B \rightarrow \Lambda | bB$ (grammar for $M$)
    \item $S \rightarrow AB$ (product rule)
\end{itemize}
\end{example}

\subsection{Closure Rule}
The grammar for the closure of a language, $L^*$, starts with the production:
\[S \rightarrow AS|\Lambda\]
Which is followed by: the grammar rules of $L$ (start symbol $A$).

\begin{example}{Grammar Closure Rule}
If we take the problem that we want to construct a language, $L$, of all possible strings made up from zero or more occurrences of $aa$ or $bb$:
\[L = \{aa, bb\}^* = M^*\]
Where $M = {aa, bb}$

Therefore:
\[L = \{\Lambda, aa, bb, aaaa, aabb, bbbb, bbaa, \ldots\}\]

Therefore, we can write a grammar for $L$ as follows:
\begin{itemize}
    \item $S \rightarrow AS | \Lambda$ (closure rule)
    \item $A \rightarrow aa|bb$ (grammar for $\{aa, bb\}$)
\end{itemize}
\end{example}

\section{Equivalent Grammars}
Grammars are not unique; a given language can have many grammars which could produce it. Grammars can be simplified down to their simplest form. 

\begin{example}{Simplifying Grammars}
If we take the grammar from the previous example:
\[S \rightarrow AS | \Lambda, \quad A \rightarrow aa|bb\]
We can simplify this:
\begin{itemize}
    \item Replace the occurrence of $A$ in $S \rightarrow AS$ by the right side of $A \rightarrow aa$ to obtain the production $S \rightarrow aaS$
    \item Replace $A$ in $S \rightarrow AS$ by the right side of $A \rightarrow bb$ to obtain the production $S \rightarrow bbS$
\end{itemize}
We can therefore write the grammar in simplified form as:
\[S \rightarrow aaS | bbS | \Lambda\]
\end{example}