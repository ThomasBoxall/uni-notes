\taughtsession{Lecture}{B4: Undecidable Problems}{2025-11-24}{15:00}{Janka}

\section{The Halting Problem}
As we saw in the last lecture - the halting problem is set around deciding if there is an algorithm that can decide whether the execution of an arbitrary program halts on an arbitrary input. 

We cna see this in action if we consider the following JavaScript programs:
\begin{verbatim}
    for(quarts = 1 ; quarts < 10 ; quarts++){
        liters = quarts/1.05671;
        alert( quarts+" "+liters);
    }
\end{verbatim}

We can clearly see that it will terminate after outputting 10 lines of output. 

\begin{verbatim}
    limit = prompt("Max Value","");
        for(quarts = 1 ; quarts < limit ; quarts++){
        liters = quarts/1.05671;
        alert( quarts+" "+liters);
    }
\end{verbatim}

The above program will alert as may times as indicated by the input.

\begin{verbatim}
    green = ON; red = amber = OFF;
    while(true){
        amber = ON; green = OFF; wait 10 seconds;
        red = ON; amber = OFF;
        wait 40 seconds; green = ON; red = OFF;
    }
\end{verbatim}

The above program will run forever, never halting. 

From these three algorithms, we learn a few things:
\begin{itemize}
    \item Algorithms may contain loops which may be infinite or finite in length
    \item The amount of work done in algorithms usually depends on the data in put
    \item Algorithms may consist of various numbers of loops, nested or in sequence.
\end{itemize}

\subsection{Solving the Halting Problem}
Using what we now know - we want to try and solve the \textit{Halting problem}. We first try running the program with the given inputs; if the program stops we know the program halts; but if the program doesn't stop in a reasonable amount of time - we cannot conclude that it won't stop as we don't know if we waited long enough or not. What is a reasonable amount of time anyway? 

The Halting problem is partially decidable. This means that there is no algorithm (and no TM) which could solve the Halting problem - meaning return the correct `YES' or `NO' answer for any input in the finite number of steps. There is only an algorithm for a finite `YES' decision. 

We can prove the Halting problem is partially decidable using a direct diagonalisation argument. 

If we define the set:
\[A = \{<M,w> : M \textrm{ is a TM that accepts } w\}\]
where $<M,w>$ is a unique coding. So we consider all possible TMs (which are countable) and all possible strings (again, countable) and if $M$ accepts $w$, it belongs to $A$. 

Another formulation of the Halting problem can be defined as: Is there a TM which will recognise the set $A$. No - there is not! However, for some simpler computing models, such as FA or PDA, we can always find a TM which recognises $A$. 

\subsection{Proving the Halting Problem}
We can prove the Halting problem using a Proof by Contradiction: \textit{Suppose there was a machine SOLVER that on every input} $w$ \textit{and for every TM} $M$ \textit{would tell us if} $M$ \textit{accepted / rejected $w$}.

If we now build a new TM, \textit{OPPOSER}, that does the following:
\begin{itemize}
    \item \textit{OPPOSER} takes the input $w$ and determines the TM $<w>$ that $w$ encodes (If the input is not the encoding of a TM then \textit{OPPOSER} rejects the input)
    \item Ask \textit{SOLVER} for the answer: ``Does the TM $<w>$ accept $w$?''
    \item If \textit{SOLVER} accepts, then \textit{OPPOSER} rejects;\\
    if \textit{SOLVER} rejects, then \textit{OPPOSER} accepts
\end{itemize}

\textit{OPPOSER} is a perfectly valid TM because \textit{SOLVER} always halts.

Let's play with this a bit now. What does \textit{OPPOSER} do if the input is the encoding of \textit{OPPOSER}. Let \textit{<OPPOSER>} = $\tilde{w}$:
\begin{itemize}
    \item \textit{OPPOSER} asks \textit{SOLVER} for an answer on ``Does the TM $<\tilde{w}>$ accept $\tilde{w}$?''
    \item If \textit{SOLVER} claims that \textit{OPPOSER} accepts $\tilde{w}$, then \textit{OPPOSER} rejects $\tilde{w}$.
    \item If \textit{SOLVER} claims that \textit{OPPOSER} rejects $\tilde{w}$, then \textit{OPPOSER} accepts $\tilde{w}$. 
\end{itemize}

This is now what was to be expected - and is the opposite to that of the above. The thing which went wrong this time around was assuming that \textit{SOLVER} exists. Meaning that \textit{SOLVER} does not exist.

The Halting problem shows that computers can't help mathematicians to solve old hard problems.

\begin{example}{Golbach's Conjecture}
If we consider a TM that tries to find a counterexample to Golbach's conjectture (from the 18th century):
\begin{center}
Every even number $\geq$ 4 is the sum of two primes.
\end{center}

The TM tries every even value of $n$ in increasing in order. For each $n$, it checks if there is a value of $i$ such that $i$, $n - i$ are primes. If not, it stops; otherwise it continues forever.

If the halting problem returns `YES' - it has found a counterexample of Goldbach's conjecture. However if the Halting problem returns `NO' - Goldbach's Conjecture is valid.

Unfortunately - the halting problem is undecidable, so computers can't help mathematicians in this way. 
\end{example}


\subsection{Proving a Problem is Undecidable}
To prove that a problem is undecidable - we have two options.

Firstly, we can use \textit{contradiction}: we start by assuming it is solvable and see if it leads to an internal contradiction, or conflicts with something else we believe is true. 

Or alternatively, we can use \textit{reduction}: see if another unsolvable problem can be reduced to solving it. This means if we assume it is solvable, then can we show that another problem we believe is unsolvable (like the Halting problem) be solved. 

The rest of this lecture will look at examples of undecidable problems.

\section{Post Correspondence Problem}
The \textit{Post Correspondence Problem} was introduced by \textit{Post} in 1946. It is a decision problem that looks at if there is a sequence of pairs of strings from a given finite set such that the concatenation of the first in pairs equals the concatenation of the second in pairs. 

We can see this formalised if we take an alphabet, $\Sigma$, and a finite sequence of pairs of strings over $\Sigma$:
\[(s_1, t_1), \ldots, (s_n, t_n)\]

We then look for a sequence of indexes $i_1, \ldots, i_k$ with repetition allowed such that:
\[s_{i_1}, \ldots, s_{i_k} = t_{i_1}, \ldots, t_{i_k}\]

\begin{example}{Post Correspondence Problems}
\textbf{Ex. 1: Valid}

If we consider an instance of the problem consisting of the following sequence of pairs over $\{a,b\}$:
\[1. (ab,a),\ 2. (aba,bb),\ 3.(aa,b),\ 4.(b,aab)\]

After some fiddling - we find out solution:
\[\underbrace{ab}_1 \underbrace{aa}_3 \underbrace{b}_4 = \underbrace{a}_1 \underbrace{b}_3 \underbrace{aab}_4\]

We see here that (1, 3, 4) is a solution.

\textbf{Ex. 2: Invalid}

We can see how an instance over $\{a,b\}$:
\[1. (ab,a),\ 2. (b,ab)\]
may not have a solution. 

\textbf{Ex. 3: Repetition}

We can take another instance of the problem, again over $\{a,b\}$:

\[1. (a,baa),\ 2.(ab,aa),\ 3.(bba,bb)\]

And we can find that:
\[\underbrace{bba}_3 \underbrace{ab}_2 \underbrace{bba}_3 \underbrace{a}_1 = \underbrace{bb}_3 \underbrace{aa}_2 \underbrace{bb}_3 \underbrace{baa}_1\]

Therefore we can see that (3,2,3,1) is a valid solution.
\end{example}

All the problems we've looked at in the above example have been reasonably small; small enough that we can just brute force the answer out of it. However this will begin to be an issue as we use larger and larger input strings. 

If there is no solution - the algorithm will just keep churning, and churning, and churning - never stopping. This means we can see that the Post correspondence problem is undecidable, but partially decidable.

\section{The Tiling Problem}
\begin{todo}
Add when I'm feeling brave with TikZ
\end{todo}

\section{Hilbert's Tenth Problem}
Hilbert's 10th problem states that: Does a polynomial equation $p(x_1, \ldots, x_n) = 0$ with integer coefficients have a solution consisting of integers.

\begin{example}{Specific Instance of Hilbert's Tenth Problem}
We can generally solve specific instances of the problem - such as integer solutions to the equation:
\[2x + 3y + 1 = 0\]
\end{example}

In 1970, Matiyasevich proved that Hilbert's tenth problem is undecidable. Meaning that there is no algorithm to decide whether an arbitrary polynomial equation with integer coefficients has a solution of integers. However this problem is partially decidable - as we can write an algorithm (or a TM) which returns a solution if the solution exists.

\section{The Equivalence Problem}
The Equivalence problem asks if there exists an algorithm that can decide whether two arbitrary computable functions produce the same output. 

We can tell that two functions, $f$ and $g$ are equal where $f(x) = x+x$ and $g(x) = 2x$. 

So is the Equivalence Problem a decidable problem? No, of course it isn't - the equivalence problem is undecidable. 

\section{The Total Problem}
The Total Problem asks if there is an algorithm to tell whether an arbitrary computer function is total. 

As we saw in DMAFP - a Total Function is one who for every input has a defined output. 

\begin{example}{A Total Problem(atic Function)}
If we take a function $f: \mathbb{N} \rightarrow \mathbb{N}$ as defined by $f(x) = x+1$ we can see that it's total.
\end{example}

The Total Problem is an undecidable problem as there is not an algorithm to answer the problem for all computable functions. 